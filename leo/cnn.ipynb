{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "from nibabel.processing import resample_to_output\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=cuda0,floatX=float32\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "import theano\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution3D, MaxPooling3D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gc</th>\n",
       "      <th>Gv</th>\n",
       "      <th>Gl</th>\n",
       "      <th>Gs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>1.023653</td>\n",
       "      <td>0.991524</td>\n",
       "      <td>0.462879</td>\n",
       "      <td>0.511900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>-0.223765</td>\n",
       "      <td>-1.001832</td>\n",
       "      <td>-1.862046</td>\n",
       "      <td>-0.327059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>-1.127033</td>\n",
       "      <td>-1.870645</td>\n",
       "      <td>-0.899005</td>\n",
       "      <td>-2.209004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>-0.063546</td>\n",
       "      <td>0.850259</td>\n",
       "      <td>0.470841</td>\n",
       "      <td>0.756666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>0.450993</td>\n",
       "      <td>0.810722</td>\n",
       "      <td>0.667942</td>\n",
       "      <td>0.606078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gc        Gv        Gl        Gs\n",
       "ID                                          \n",
       "1105  1.023653  0.991524  0.462879  0.511900\n",
       "1125 -0.223765 -1.001832 -1.862046 -0.327059\n",
       "1130 -1.127033 -1.870645 -0.899005 -2.209004\n",
       "1362 -0.063546  0.850259  0.470841  0.756666\n",
       "1381  0.450993  0.810722  0.667942  0.606078"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero-pad some of the entries so they match the filenames\n",
    "df = pd.read_csv('C:/Users/Leo/Documents/GradSchool/2018_IA_Hackathon/data/phenotype/phenotype_t1.csv',\n",
    "                converters={'ID': lambda x: str(x).zfill(4)})\n",
    "# make the ID the index in the pandas dataframe\n",
    "df.set_index('ID', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = list()\n",
    "i=1\n",
    "labels = []\n",
    "pheno = []\n",
    "lesion_masks = glob('C:/Users/Leo/Documents/GradSchool/2018_IA_Hackathon/data/Hackathon_Lesion_Data/LESYMAP_trainingSet/*.nii.gz')\n",
    "for les_file in lesion_masks:\n",
    "    match = re.match(r'.*\\\\([0-9]{4}).nii.gz', les_file)\n",
    "    sub_id = match.groups()[0]\n",
    "    if sub_id in df.index:   \n",
    "        pheno.append(df.loc[sub_id]['Gc'])\n",
    "        labels.append(sub_id)\n",
    "        les_img = nib.load(les_file)\n",
    "        les_img_resamp = resample_to_output(les_img, voxel_sizes=(3, 3, 3))\n",
    "        les_data = les_img_resamp.get_data()\n",
    "        data.append(les_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.array(data, dtype=\"float\")\n",
    "labels_array = np.array(labels, dtype=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cad372c7f0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_array[0,20,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the labels\n",
    "Y = pheno / np.linalg.norm(pheno)\n",
    "\n",
    "# Format\n",
    "X = data_array.reshape(data_array.shape[0], 1, *data_array.shape[1:4])\n",
    "input_shape = X[0].shape\n",
    "\n",
    "#(trainX, testX, trainY, testY) = train_test_split(data_array, pheno_normalized, test_size=0.1, random_state=seed)\n",
    "\n",
    "#trainX = trainX.reshape(trainX.shape[0], 1, *trainX.shape[1:4])\n",
    "#testX = testX.reshape(testX.shape[0], 1, *testX.shape[1:4])\n",
    "\n",
    "#input_shape = trainX[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv3D, MaxPooling3D\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pylab as plt\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    " \n",
    "model.add(Convolution3D(32, (5,5,5), activation='relu', input_shape=input_shape, data_format = 'channels_first'))\n",
    "model.add(Convolution3D(32, (5,5,5), activation='relu', input_shape=input_shape, data_format = 'channels_first'))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model.add(Convolution3D(64, (2,2,2), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model.add(Convolution3D(64, (2,2,2), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH = 25\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae'])\n",
    "early_stopper = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=5,\n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72 samples, validate on 9 samples\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 21s 296ms/step - loss: 0.0134 - mean_absolute_error: 0.0896 - val_loss: 0.0106 - val_mean_absolute_error: 0.0927\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0089 - mean_absolute_error: 0.0757 - val_loss: 0.0090 - val_mean_absolute_error: 0.0813\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0070 - mean_absolute_error: 0.0674 - val_loss: 0.0100 - val_mean_absolute_error: 0.0871\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.0059 - mean_absolute_error: 0.0635 - val_loss: 0.0094 - val_mean_absolute_error: 0.0807\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0053 - mean_absolute_error: 0.0582 - val_loss: 0.0109 - val_mean_absolute_error: 0.1004\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0054 - mean_absolute_error: 0.0599 - val_loss: 0.0082 - val_mean_absolute_error: 0.0776\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0033 - mean_absolute_error: 0.0459 - val_loss: 0.0075 - val_mean_absolute_error: 0.0713\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.0030 - mean_absolute_error: 0.0422 - val_loss: 0.0080 - val_mean_absolute_error: 0.0758\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.0018 - mean_absolute_error: 0.0305 - val_loss: 0.0085 - val_mean_absolute_error: 0.0775\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.0019 - mean_absolute_error: 0.0329 - val_loss: 0.0086 - val_mean_absolute_error: 0.0841\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), \n",
    "          batch_size=BATCH, nb_epoch=10, verbose=1, callbacks=[early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1, 62, 74, 62)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:20].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(1) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-e5e378c0a89b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \"\"\"\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 142\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array(1) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "kfold.split(range(0,20), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=10, random_state=42, shuffle=True)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.0713 - mean_absolute_error: 0.1795\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:535: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mean_absolute_error\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0127 - mean_absolute_error: 0.0915\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0125 - mean_absolute_error: 0.0902\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0116 - mean_absolute_error: 0.0864\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0088 - mean_absolute_error: 0.0741\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0078 - mean_absolute_error: 0.0714\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0080 - mean_absolute_error: 0.0710\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0066 - mean_absolute_error: 0.0660\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.0062 - mean_absolute_error: 0.0618\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0049 - mean_absolute_error: 0.0548\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0039 - mean_absolute_error: 0.0476\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.0034 - mean_absolute_error: 0.0442\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0030 - mean_absolute_error: 0.0418\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.0028 - mean_absolute_error: 0.0405\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.0023 - mean_absolute_error: 0.0353\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.0022 - mean_absolute_error: 0.0344\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.0017 - mean_absolute_error: 0.0302\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.0013 - mean_absolute_error: 0.0256\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.0012 - mean_absolute_error: 0.0243\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.0011 - mean_absolute_error: 0.0248\n",
      "mean_absolute_error: 8.10%\n",
      "Epoch 1/20\n",
      "73/73 [==============================] - 16s 219ms/step - loss: 0.0822 - mean_absolute_error: 0.1998\n",
      "Epoch 2/20\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.0152 - mean_absolute_error: 0.0981\n",
      "Epoch 3/20\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 0.0130 - mean_absolute_error: 0.0917\n",
      "Epoch 4/20\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.0129 - mean_absolute_error: 0.0914\n",
      "Epoch 5/20\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0127 - mean_absolute_error: 0.0908\n",
      "Epoch 6/20\n",
      "73/73 [==============================] - 5s 68ms/step - loss: 0.0125 - mean_absolute_error: 0.0902\n",
      "Epoch 7/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.0117 - mean_absolute_error: 0.0874\n",
      "Epoch 8/20\n",
      "73/73 [==============================] - 6s 77ms/step - loss: 0.0108 - mean_absolute_error: 0.0826\n",
      "Epoch 9/20\n",
      "73/73 [==============================] - 5s 73ms/step - loss: 0.0092 - mean_absolute_error: 0.0773\n",
      "Epoch 10/20\n",
      "73/73 [==============================] - 5s 72ms/step - loss: 0.0089 - mean_absolute_error: 0.0740\n",
      "Epoch 11/20\n",
      "73/73 [==============================] - 6s 77ms/step - loss: 0.0083 - mean_absolute_error: 0.0740\n",
      "Epoch 12/20\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0079 - mean_absolute_error: 0.0723\n",
      "Epoch 13/20\n",
      "73/73 [==============================] - 5s 72ms/step - loss: 0.0078 - mean_absolute_error: 0.0728\n",
      "Epoch 14/20\n",
      "73/73 [==============================] - 5s 72ms/step - loss: 0.0077 - mean_absolute_error: 0.0694\n",
      "Epoch 15/20\n",
      "73/73 [==============================] - 5s 73ms/step - loss: 0.0071 - mean_absolute_error: 0.0678\n",
      "Epoch 16/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.0067 - mean_absolute_error: 0.0669\n",
      "Epoch 17/20\n",
      "73/73 [==============================] - 7s 100ms/step - loss: 0.0056 - mean_absolute_error: 0.0589\n",
      "Epoch 18/20\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.0053 - mean_absolute_error: 0.0553\n",
      "Epoch 19/20\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0048 - mean_absolute_error: 0.0526\n",
      "Epoch 20/20\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.0043 - mean_absolute_error: 0.0516\n",
      "mean_absolute_error: 7.12%\n",
      "Epoch 1/20\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.0945 - mean_absolute_error: 0.2190\n",
      "Epoch 2/20\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.0103 - mean_absolute_error: 0.0852\n",
      "Epoch 3/20\n",
      "73/73 [==============================] - 5s 71ms/step - loss: 0.0111 - mean_absolute_error: 0.0872\n",
      "Epoch 4/20\n",
      "73/73 [==============================] - 5s 71ms/step - loss: 0.0103 - mean_absolute_error: 0.0835\n",
      "Epoch 5/20\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0099 - mean_absolute_error: 0.0818\n",
      "Epoch 6/20\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0092 - mean_absolute_error: 0.0781\n",
      "Epoch 7/20\n",
      "73/73 [==============================] - 6s 75ms/step - loss: 0.0088 - mean_absolute_error: 0.0761\n",
      "Epoch 8/20\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0084 - mean_absolute_error: 0.0741\n",
      "Epoch 9/20\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0079 - mean_absolute_error: 0.0707\n",
      "Epoch 10/20\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0077 - mean_absolute_error: 0.0716\n",
      "Epoch 11/20\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.0074 - mean_absolute_error: 0.0703\n",
      "Epoch 12/20\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0066 - mean_absolute_error: 0.0636\n",
      "Epoch 13/20\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.0067 - mean_absolute_error: 0.0654\n",
      "Epoch 14/20\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0059 - mean_absolute_error: 0.0588\n",
      "Epoch 15/20\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0056 - mean_absolute_error: 0.0575\n",
      "Epoch 16/20\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0053 - mean_absolute_error: 0.0565\n",
      "Epoch 17/20\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0048 - mean_absolute_error: 0.0565\n",
      "Epoch 18/20\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.0047 - mean_absolute_error: 0.0537\n",
      "Epoch 19/20\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0041 - mean_absolute_error: 0.0503\n",
      "Epoch 20/20\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.0037 - mean_absolute_error: 0.0471\n",
      "mean_absolute_error: 12.73%\n",
      "Epoch 1/20\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.0488 - mean_absolute_error: 0.1673\n",
      "Epoch 2/20\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.0125 - mean_absolute_error: 0.0919\n",
      "Epoch 3/20\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0113 - mean_absolute_error: 0.0865\n",
      "Epoch 4/20\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0105 - mean_absolute_error: 0.0833\n",
      "Epoch 5/20\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0090 - mean_absolute_error: 0.0771\n",
      "Epoch 6/20\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.0089 - mean_absolute_error: 0.0775\n",
      "Epoch 7/20\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0080 - mean_absolute_error: 0.0716\n",
      "Epoch 8/20\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.0082 - mean_absolute_error: 0.0742\n",
      "Epoch 9/20\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0073 - mean_absolute_error: 0.0687\n",
      "Epoch 10/20\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0067 - mean_absolute_error: 0.0677\n",
      "Epoch 11/20\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.0061 - mean_absolute_error: 0.0620\n",
      "Epoch 12/20\n",
      "73/73 [==============================] - 5s 75ms/step - loss: 0.0054 - mean_absolute_error: 0.0592\n",
      "Epoch 13/20\n",
      "73/73 [==============================] - 5s 69ms/step - loss: 0.0045 - mean_absolute_error: 0.0521\n",
      "Epoch 14/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.0039 - mean_absolute_error: 0.0490\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 5s 68ms/step - loss: 0.0033 - mean_absolute_error: 0.0444\n",
      "Epoch 16/20\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.0027 - mean_absolute_error: 0.0415\n",
      "Epoch 17/20\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.0028 - mean_absolute_error: 0.0408\n",
      "Epoch 18/20\n",
      "73/73 [==============================] - 6s 76ms/step - loss: 0.0025 - mean_absolute_error: 0.0377\n",
      "Epoch 19/20\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.0024 - mean_absolute_error: 0.0385\n",
      "Epoch 20/20\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.0021 - mean_absolute_error: 0.0344\n",
      "mean_absolute_error: 9.02%\n",
      "Epoch 1/20\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.0625 - mean_absolute_error: 0.1834\n",
      "Epoch 2/20\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.0122 - mean_absolute_error: 0.0886\n",
      "Epoch 3/20\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.0121 - mean_absolute_error: 0.0888\n",
      "Epoch 4/20\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.0106 - mean_absolute_error: 0.0837\n",
      "Epoch 5/20\n",
      "50/73 [===================>..........] - ETA: 1s - loss: 0.0074 - mean_absolute_error: 0.0666"
     ]
    }
   ],
   "source": [
    "# training param\n",
    "EPOCHS = 20\n",
    "BATCH = 25\n",
    "early_stopper = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=5,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(range(X.shape[0])):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution3D(32, (5,5,5), activation='relu', input_shape=input_shape, data_format = 'channels_first'))\n",
    "    model.add(Convolution3D(32, (5,5,5), activation='relu', input_shape=input_shape, data_format = 'channels_first'))\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "    model.add(Convolution3D(64, (2,2,2), activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "    model.add(Convolution3D(64, (2,2,2), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='tanh'))# Compile model\n",
    "    \n",
    "    model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X[train], Y[train], batch_size=BATCH,\n",
    "              nb_epoch=EPOCHS, verbose=1, callbacks=[early_stopper])\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x000001CC01D17150>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
